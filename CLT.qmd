---
title: "The Effects of Skewness on the Central Limit Theorem"
author: "Visruth Srimath Kandali, Beth Chance, California Polytechnic San Luis Obispo Department of Statistics"
format: html
embed-resources: true
# engine: julia # min Quarto 1.5
---

## Creating the Data

```{julia sampling distribution}
#| output: false
using Distributions, Random, DataFrames, CSV, StatsBase

function standardize(x, μ, σ, n::Int64)::Float64
    (x - μ) / (σ / sqrt(n))
end

function sampling_distribution(statistic::Function, d::Distribution, n::Int, r::Int; args...)::Vector{Float64}
    Random.seed!(0)
    # Preallocating vectors for speed
    sample_statistics = zeros(r)
    sample = zeros(n)

    # Sampling r times and calculating the statistic
    @inbounds for i in 1:r
        rand!(d, sample) # in-place to reduce memory allocation
        sample_statistics[i] = statistic(sample; args...)::Float64
    end

    sample_statistics
end
```

This function creates a sampling distribution, using the given distribution and its parameters. It takes samples of size `n` and calculates each sample's `statistic`. It does this \`r\` times to create a sampling distribution and mitigate any concerns of natural sampling variability. It returns this sampling distribution for further analysis.

```{julia Single distribution analysis}
#| output: false
function analysis(statistic::Function, d::Distribution, n::Int, r::Int, μ::Real, σ::Real, critical::Float64; args...)::Tuple{Float64,Float64,Float64,Float64}
    statistics = sampling_distribution(statistic, d, n, r; args...)
    skewness = StatsBase.skewness(statistics)
    kurtosis = StatsBase.kurtosis(statistics)

    # Standardizing the values to look at tail probabilities
    z_scores = zeros(r)
    zscore!(z_scores, statistics, mean(statistics), std(statistics))

    # Calculating tail probabilities
    upper = sum(z_scores .>= critical) / r
    lower = sum(z_scores .<= -critical) / r

    (upper, lower, skewness, kurtosis)
end
```

This function then finds the upper and lower tails of this sampling distribution under the assumption that it is normally distributed by looking at z-scores more extreme than $\pm$ 1.96. The function returns the tail weights along with the skewness and kurtosis of the sampling distribution.

```{julia Analyzing multiple distributions}
#| output: false
function analyze_distributions(statistic::Function, r::Int, sample_sizes::Vector{Int}, critical::Function, distributions, params=false)::DataFrame
    println("Analyzing sampling distributions of $(statistic) with $(r) repetitions")
    # Setting up the results we're interested in
    results = DataFrame(
        "Distribution" => String[],
        "Skewness" => Float64[],
        "Sample Size" => Int64[],
        "Upper Tail" => Float64[],
        "Lower Tail" => Float64[],
        "Sampling Skewness" => Float64[],
        "Sampling Kurtosis" => Float64[],
        "Population Mean" => Float64[],
        "Population SD" => Float64[]
    )

    # Analyzing each distribution
    @inbounds for d::Distribution in distributions
        println(string(d))

        # Getting population parameters
        μ = mean(d)
        σ = std(d)
        skewness = StatsBase.skewness(d)

        # Analyzing each sample size
        u = Threads.SpinLock() # lock to avoid data races
        @inbounds Threads.@threads for n in sample_sizes
            if params
                upper, lower, sample_skewness, sample_kurtosis = analysis(statistic, d, n, r, μ, σ, abs(critical(n)), μ=μ)
            else
                upper, lower, sample_skewness, sample_kurtosis = analysis(statistic, d, n, r, μ, σ, abs(critical(n)))
            end
            Threads.lock(u) do
                push!(results, (string(d), skewness, n, upper, lower, sample_skewness, sample_kurtosis, μ, σ))
            end
        end

    end

    sort!(results, [:Distribution, :"Sample Size"])
end
```

```{julia Generate data}
#| output: false
function main(r)
    sample_sizes = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 125, 150, 175, 200, 250, 300, 350, 400, 450, 500]
    distributions = [
        Gamma(16),
        LogNormal(0, 0.25),
        Gamma(4),
        Gamma(2),
        LogNormal(0, 0.5),
        Gamma(1),
        Exponential(),
        Gamma(0.64),
        LogNormal(0, 0.75)
    ]
    # tstar = n -> quantile(TDist(n), 0.975)
    zstar = n -> quantile(Normal(), 0.975)

    # Compile
    analyze_distributions(mean, 1, sample_sizes, zstar, distributions)
    # analyze_distributions(t_score, 1, sample_sizes, tstar, distributions, true)

    # Warning: this code will take a very long time to run if used with a large r. We used r = 10_000_000
    @time means::DataFrame = analyze_distributions(mean, r, sample_sizes, zstar, distributions)
    CSV.write("means.csv", means)

    # @time t::DataFrame = analyze_distributions(t_score, r, sample_sizes, tstar, distributions, true)
    # CSV.write("t.csv", t)

    nothing
end

main(1_000_000) # remove this if you want to render the document but already have data
```

We used r = 1,000,000 repetitions to create our sampling distributions of means (means.csv). Keep in mind that, while Julia is fast, this is a non-trivial task and will take some time. It is highly recommended to run the code in a Julia REPL instead of this notebook.

## Analyzing the Data

```{r setup}
library(tidyverse)
library(flextable)

df <- read_csv("means.csv") |>
  group_by(Distribution) |>
  mutate(Distribution = str_replace(Distribution, "\\{.*\\}", " ")) |>
  filter(
    `Lower Tail` >= 0.02 & `Lower Tail` <= 0.03,
    `Upper Tail` >= 0.02 & `Upper Tail` <= 0.03
  ) |>
  # filter(`Sampling Skewness` <= 1/6) |>
  filter(`Sample Size` == min(`Sample Size`)) |> # get the smallest sample size for each distribution
  select(Distribution, Skewness, `Sampling Skewness`, `Sample Size`) |>
  arrange(Skewness, Distribution)

ft <- flextable(df) |>
  colformat_double(j = c("Skewness", "Sampling Skewness"), digits = 3) |>
  font(fontname = "Trebuchet MS") |>
  autofit()

save_as_image(ft, path = "Poster//table.png", res = 2000)
ft
```

Now that we have the data, we may proceed with our analysis. We judged normality by looking at tailed-ness; we treated a distribution as normal if both of its tails were within 20% of 0.025 as that is what we would expect from a Normal distribution.

```{r Fitting the model}
model <- lm(Skewness ~ sqrt(`Sample Size`), df)
df |>
  ggplot(aes(x = sqrt(`Sample Size`), y = Skewness, label = Distribution)) +
  geom_abline(
    slope = coef(model)[2],
    intercept = coef(model)[1],
    color = "blue",
    linetype = "dashed",
    linewidth = 1.5
  ) +
  geom_line(linewidth = 1.5) +
  geom_point(size = 3) +
  ggrepel::geom_label_repel(seed = 0, nudge_x = 1, size = 5) +
  labs(
    title = "Linear Relationship between Skewness and Empirical Minimum Square Root Sample Size",
    x = "Square Root of Sample Size",
    y = "Skewness"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 23),
    axis.title = element_text(size = 17),
    axis.text = element_text(size = 12)
  )

ggsave("Poster//Skew_Sample_Size.png", width = 15, height = 8.5, dpi = 1000)

summary(model)
```

We ran a linear regression to determine that if $n\geq36*skewness^2$ the sampling distribution of the means will be approximately normal as prior defined. We also plot the relationship between skewness and empirical sampling size that we found.

## Generating Some Graphs

This section is dedicated to creating data and graphs for the poster and paper.

```{julia Generating Exponential data for graphing}
function graphing(r)
    d = Exponential()
    n = 30

    # Creating sampling distributions
    exponential30 = sampling_distribution(mean, d, n, r)
    exponential30std = standardize(exponential30)

    n = 150
    exponential150 = sampling_distribution(mean, d, n, r)
    exponential150std = standardize(exponential150)

    graphing = DataFrame(
        "Exponential 30" => exponential30,
        "Exponential 30 Z-Scores" => exponential30std,
        "Exponential 150" => exponential150,
        "Exponential 150 Z-Scores" => exponential150std
    )

    CSV.write("graphing.csv", graphing)

    nothing
end

graphing(1_000_000)
```

We create the data used to graph the exponential sampling distributions.

```{r Graphing exponential sampling distributions}
#| message: false
graphing <- read_csv("graphing.csv")
# Create exponential population plot
x <- seq(0, 5, length.out = 100)
y <- dexp(x, rate = 1)
sub <- ggplot() +
  geom_line(aes(x, y)) +
  labs(
    title = "Exponential Population with Rate = 1"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(size = 12),
    axis.text = element_blank(),
    axis.title = element_blank(),
    axis.ticks = element_blank()
  )

for (col_name in colnames(
  graphing |>
    select("Exponential 30 Z-Scores", "Exponential 150 Z-Scores")
)) {
  sample_size <- str_extract(col_name, "\\d+")

  upper <- sum(graphing[[col_name]] >= 1.96) / length(graphing[[col_name]])
  lower <- sum(graphing[[col_name]] <= -1.96) / length(graphing[[col_name]])

  main <- ggplot(graphing, aes(x = .data[[col_name]])) +
    geom_histogram(bins = 100, aes(y = after_stat(density))) +
    stat_function(
      fun = dnorm,
      args = list(
        mean = mean(graphing[[col_name]]),
        sd = sd(graphing[[col_name]])
      ),
      color = "blue",
      linewidth = 1.25
    ) +
    geom_vline(xintercept = 1.96, linetype = "dashed", color = "blue") +
    annotate(
      "text",
      x = 2.5,
      y = 0.1,
      label = "1.96 SDs",
      color = "blue",
      size = 5
    ) +
    annotate(
      "text",
      x = -2.5,
      y = 0.1,
      label = "-1.96 SDs",
      color = "blue",
      size = 5
    ) +
    annotate(
      "text",
      x = 3,
      y = 0.05,
      label = round(upper, 4),
      color = "black",
      size = 5
    ) +
    annotate(
      "text",
      x = -3,
      y = 0.05,
      label = round(lower, 4),
      color = "black",
      size = 5
    ) +
    geom_vline(xintercept = -1.96, linetype = "dashed", color = "blue") +
    labs(
      title = paste(
        "Sampling Distribution of Standardized Means for n =",
        sample_size
      ),
      x = "Z Score",
      y = "Frequency"
    ) +
    theme_bw() +
    theme(
      plot.title = element_text(size = 20),
      axis.title = element_text(size = 17),
      axis.text = element_text(size = 12)
    )

  combined <- main + patchwork::inset_element(sub, 0.6, 0.6, 1, 1)

  ggsave(
    paste0(
      "Poster//",
      str_replace(str_sub(col_name, 1, -10), " ", "_"),
      ".png"
    ),
    plot = combined,
    width = 12,
    height = 6.75,
    dpi = 200
  )
}
```

We create two sampling distributions of the Exponential distribution, which has a skewness of 2, to show how the distribution converges to a Normal distribution as sample size increases. We only look at n = 30 and n = 150 to compare the old guideline with the new one.

```{r Graphing normal sampling distribution}
x <- seq(-5, 5, length.out = 100)
y <- dnorm(x)
sub <- ggplot() +
  geom_line(aes(x, y)) +
  labs(
    title = "Standard Normal Population"
  ) +
  theme_classic() +
  theme(
    plot.title = element_text(size = 12),
    axis.text = element_blank(),
    axis.title = element_blank(),
    axis.ticks = element_blank()
  )

for (col_name in colnames(
  graphing |>
    # select("Normal 5 Z-Scores", "Normal 10 Z-Scores", "Normal 30 Z-Scores")
    select("Normal 10 Z-Scores")
)) {
  sample_size <- str_extract(col_name, "\\d+")

  upper <- sum(graphing[[col_name]] >= 1.96) / length(graphing[[col_name]])
  lower <- sum(graphing[[col_name]] <= -1.96) / length(graphing[[col_name]])

  main <- ggplot(graphing, aes(x = .data[[col_name]])) +
    geom_histogram(bins = 100, aes(y = after_stat(density))) +
    stat_function(
      fun = dnorm,
      args = list(
        mean = mean(graphing[[col_name]]),
        sd = sd(graphing[[col_name]])
      ),
      color = "blue",
      linewidth = 1.25
    ) +
    geom_vline(xintercept = 1.96, linetype = "dashed", color = "blue") +
    annotate(
      "text",
      x = 2.5,
      y = 0.1,
      label = "1.96 SDs",
      color = "blue",
      size = 5
    ) +
    annotate(
      "text",
      x = -2.5,
      y = 0.1,
      label = "-1.96 SDs",
      color = "blue",
      size = 5
    ) +
    annotate(
      "text",
      x = 3,
      y = 0.05,
      label = round(upper, 4),
      color = "black",
      size = 5
    ) +
    annotate(
      "text",
      x = -3,
      y = 0.05,
      label = round(lower, 4),
      color = "black",
      size = 5
    ) +
    geom_vline(xintercept = -1.96, linetype = "dashed", color = "blue") +
    labs(
      title = paste(
        "Sampling Distribution of Standardized Means for n =",
        sample_size
      ),
      x = "Z Score",
      y = "Frequency"
    ) +
    theme_bw() +
    theme(
      plot.title = element_text(size = 20),
      axis.title = element_text(size = 17),
      axis.text = element_text(size = 12)
    )

  combined <- main + patchwork::inset_element(sub, 0.6, 0.6, 1, 1)

  ggsave(
    paste0(
      "Poster//",
      str_replace(str_sub(col_name, 1, -10), " ", "_"),
      ".png"
    ),
    plot = combined,
    width = 12,
    height = 6.75,
    dpi = 200
  )
}
```

```{r Graphing tails}
read_csv("means.csv") |>
  mutate(
    Distribution = paste(
      str_replace(Distribution, "\\{.*\\}", " "),
      round(Skewness, 2)
    ),
    Distribution = factor(
      Distribution,
      levels = unique(Distribution[order(-Skewness)])
    )
  ) |>
  arrange(Skewness) |>
  ggplot(aes(x = `Sample Size`, color = Distribution)) +
  geom_rect(
    aes(xmin = 0, xmax = Inf, ymin = 0.02, ymax = 0.03),
    fill = "grey",
    linewidth = 0
  ) +
  geom_hline(yintercept = 0.025, linetype = "dashed", linewidth = 1) +
  geom_line(aes(y = `Upper Tail`), linewidth = 1) +
  geom_line(aes(y = `Lower Tail`), linewidth = 1) +
  geom_vline(xintercept = 30, linetype = "dashed", linewidth = 0.75) +
  annotate(
    "text",
    x = 40,
    y = 0.04,
    label = "n = 30",
    hjust = 0,
    size = 5,
    color = "black"
  ) +
  labs(
    title = "Upper and Lower Tail Weights of Sampling Distributions",
    x = "Sample Size",
    y = "Tail Weight"
  ) +
  theme_bw() +
  theme(
    plot.title = element_text(size = 23),
    axis.title = element_text(size = 17),
    axis.text = element_text(size = 12)
  )


ggsave("Poster//Tail_Weights.png", width = 12, height = 6.75, dpi = 1000)
```

The convergence rate of a sampling distribution, as shown by the Berry-Essen theorem, is related to the third absolute normalized moment. Skewness directly affects the convergence rate as our skewness shows, and this graph shows the change in tailedness of skewed distributions as sample size changes. The highlighted area is what used as a threshold for normality–both tails being within 20% of 0.025.